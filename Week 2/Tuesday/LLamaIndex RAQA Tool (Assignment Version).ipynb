{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a more robust RAQA system using LlamaIndex\n",
    "\n",
    "We'll be putting together a system for querying both qualitative and quantitative data using LlamaIndex. \n",
    "\n",
    "To stick to a theme, we'll continue to use BarbenHeimer data as our base - but this can, and should, be extended to other topics/domains.\n",
    "\n",
    "# Build 🏗️\n",
    "There are 3 main tasks in this notebook:\n",
    "\n",
    "- Create a Qualitative VectorStore query engine\n",
    "- Create a quantitative NLtoSQL query engine\n",
    "- Combine the two using LlamaIndex's OpenAI agent framework.\n",
    "\n",
    "# Ship 🚢\n",
    "Create an host a Gradio or Chainlit application to serve your project on Hugging Face spaces.\n",
    "\n",
    "# Share 🚀\n",
    "Make a social media post about your final application and tag @AIMakerspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on terminology:\n",
    "\n",
    "You'll notice that there are quite a few similarities between LangChain and LlamaIndex. LlamaIndex can largely be thought of as an extension to LangChain, in some ways - but they moved some of the language around. Let's spend a few moments disambiguating the language.\n",
    "\n",
    "- `QueryEngine` -> `RetrievalQA`:\n",
    "  -  `QueryEngine` is just LlamaIndex's way of indicating something is an LLM \"chain\" on top of a retrieval system\n",
    "- `OpenAIAgent` vs. `ZeroShotAgent`:\n",
    "  - The two agents have the same fundamental pattern: Decide which of a list of tools to use to answer a user's query.\n",
    "  - `OpenAIAgent` (LlamaIndex's primary agent) does not need to rely on an agent excecutor due to the fact that it is leveraging OpenAI's [functional api](https://openai.com/blog/function-calling-and-other-api-updates) which allows the agent to interface \"directly\" with the tools instead of operating through an intermediary application process.\n",
    "\n",
    "There is, however, a much large terminological difference when it comes to discussing data.\n",
    "\n",
    "##### Nodes vs. Documents\n",
    "\n",
    "As you're aware of from the previous weeks assignments, there's an idea of `documents` in NLP which refers to text objects that exist within a corpus of documents.\n",
    "\n",
    "LlamaIndex takes this a step further and reclassifies `documents` as `nodes`. Confusingly, it refers to the `Source Document` as simply `Documents`.\n",
    "\n",
    "The `Document` -> `node` structure is, almost exactly, equivalent to the `Source Document` -> `Document` structure found in LangChain - but the new terminology comes with some clarity about different structure-indices. \n",
    "\n",
    "We won't be leveraging those structured indicies today, but we will be leveraging a \"benefit\" of the `node` structure that exists as a default in LlamaIndex, which is the ability to quickly filter nodes based on their metadata.\n",
    "\n",
    "![image](https://i.imgur.com/B1QDjs5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOILERPLATE\n",
    "\n",
    "This is only relevant when running the code in a Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest_asyncio in c:\\users\\damia\\documents\\github\\llm-ops-cohort-1\\myenv\\lib\\site-packages (1.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# pip install nest_asyncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary Dependencies and Context Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies and OpenAI API key setting\n",
    "\n",
    "First of all, we'll need our primary libraries - and to set up our OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-core 0.1.24 requires langsmith<0.2.0,>=0.1.0, but you have langsmith 0.0.92 which is incompatible.\n",
      "langchain-community 0.0.21 requires langsmith<0.2.0,>=0.1.0, but you have langsmith 0.0.92 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U -q openai==0.27.8 llama-index==0.8.6 nltk==3.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "import openai\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context Setting\n",
    "\n",
    "Now, LlamaIndex has the ability to set `ServiceContext`. You can think of this as a config file of sorts. The basic idea here is that we use this to establish some core properties and then can pass it to various services. \n",
    "\n",
    "While we could set this up as a global context, we're going to leave it as `ServiceContext` so we can see where it's applied.\n",
    "\n",
    "We'll set a few significant contexts:\n",
    "\n",
    "- `chunk_size` - this is what it says on the tin\n",
    "- `llm` - this is where we can set what model we wish to use as our primary LLM when we're making `QueryEngine`s and more\n",
    "- `embed_model` - this will help us keep our embedding model consistent across use cases\n",
    "\n",
    "\n",
    "We'll also create some resources we're going to keep consistent across all of our indices today.\n",
    "\n",
    "- `text_splitter` - This is what we'll use to split our text, feel free to experiment here\n",
    "- `SimpleNodeParser` - This is what will work in tandem with the `text_splitter` to parse our full sized documents into nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from llama_index import ServiceContext\n",
    "from llama_index.node_parser.simple import SimpleNodeParser\n",
    "from llama_index.langchain_helpers.text_splitter import TokenTextSplitter\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "embed_model = OpenAIEmbedding()\n",
    "chunk_size = 500\n",
    "llm = OpenAI(\n",
    "    temperature=0, \n",
    "    model=\"gpt-3.5-turbo\", \n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, \n",
    "    chunk_size=chunk_size, \n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "text_splitter = TokenTextSplitter(\n",
    "    chunk_size=50\n",
    ")\n",
    "\n",
    "node_parser = SimpleNodeParser(\n",
    "    text_splitter=text_splitter\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BarbenHeimer Wikipedia Retrieval Tool\n",
    "\n",
    "Now we can get to work creating our semantic `QueryEngine`!\n",
    "\n",
    "We'll follow a similar pattern as we did with LangChain here - and the first step (as always) is to get dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for chroma-hnswlib (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [5 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_ext\n",
      "      building 'hnswlib' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for chroma-hnswlib\n",
      "ERROR: Could not build wheels for chroma-hnswlib, which is required to install pyproject.toml-based projects\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U -q chromadb==0.4.6 tiktoken==0.4.0 sentence-transformers==2.2.2 pydantic==1.10.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "from llama_index.vector_stores import ChromaVectorStore\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChromaDB\n",
    "\n",
    "We'll be using [ChromaDB](https://www.trychroma.com/) as our `VectorStore` today!\n",
    "\n",
    "It works in a similar fashion to tools like Pinecone, Weaveate, and more - but it's locally hosted and will serve our purposes fine.\n",
    "\n",
    "You'll also notice the return of `OpenAIEmbedding()`, which is the embeddings model we'll be leveraging. Of course, this is using the `ada` model under the hood - and already comes equipped with in-memory caching.\n",
    "\n",
    "You'll notice we can pass our `service_context` into our `VectorStoreIndex`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.create_collection(\"wikipedia_barbie_opp\")\n",
    "\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "wiki_vector_index = VectorStoreIndex([], storage_context=storage_context, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U -q wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially the same as the LangChain example - we're just going to be pulling information straight from Wikipedia using the built in `WikipediaReader`.\n",
    "\n",
    "Setting `auto_suggest=False` ensures we run into fewer auto-correct based errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.wikipedia import WikipediaReader\n",
    "\n",
    "movie_list = [\"Barbie (film)\", \"Oppenheimer (film)\"]\n",
    "\n",
    "wiki_docs = WikipediaReader().load_data(pages=movie_list, auto_suggest=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node Construction\n",
    "\n",
    "Now we will loop through our documents and metadata and construct nodes (associated with particular metadata for easy filtration later).\n",
    "\n",
    "We're using the `node_parser` we created at the top of the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for movie, wiki_doc in zip(movie_list, wiki_docs):\n",
    "    parser = node_parser\n",
    "    nodes = parser.get_nodes_from_documents([wiki_doc])\n",
    "    for node in nodes:\n",
    "        node.metadata = {\"title\": movie}\n",
    "    \n",
    "    wiki_vector_index.insert_nodes(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auto Retriever Functional Tool\n",
    "\n",
    "This tool will leverage OpenAI's functional endpoint to select the correct metadata filter and query the filtered index - only looking at nodes with the desired metadata.\n",
    "\n",
    "A simplified diagram: ![image](https://i.imgur.com/AICDPav.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create our `VectoreStoreInfo` object which will hold all the relevant metadata we need for each component (in this case title metadata).\n",
    "\n",
    "Notice that you need to include it in a text list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools import FunctionTool\n",
    "from llama_index.vector_stores.types import (\n",
    "    VectorStoreInfo,\n",
    "    MetadataInfo,\n",
    "    ExactMatchFilter,\n",
    "    MetadataFilters,\n",
    ")\n",
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "\n",
    "from typing import List, Tuple, Any\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "top_k = 3\n",
    "\n",
    "vector_store_info = VectorStoreInfo(\n",
    "    content_info=\"semantic information about movies\",\n",
    "    metadata_info=[MetadataInfo(\n",
    "        name=\"title\",\n",
    "        type=\"str\",\n",
    "        description=\"title of the movie, one of [Barbie (film), Oppenheimer (film)]\",\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create our base PyDantic object that we can use to ensure compatability with our application layer. This verifies that the response from the OpenAI endpoint conforms to this schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRetrieveModel(BaseModel):\n",
    "    query: str = Field(..., description=\"natural language query string\")\n",
    "    filter_key_list: List[str] = Field(\n",
    "        ..., description=\"List of metadata filter field names\"\n",
    "    )\n",
    "    filter_value_list: List[str] = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"List of metadata filter field values (corresponding to names specified in filter_key_list)\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build our function that we will use to query the functional endpoint.\n",
    "\n",
    ">The `docstring` is important to the functionality of the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_retrieve_fn(\n",
    "    query: str, filter_key_list: List[str], filter_value_list: List[str]\n",
    "):\n",
    "    \"\"\"Auto retrieval function.\n",
    "\n",
    "    Performs auto-retrieval from a vector database, and then applies a set of filters.\n",
    "\n",
    "    \"\"\"\n",
    "    query = query or \"Query\"\n",
    "\n",
    "    exact_match_filters = [\n",
    "        ExactMatchFilter(key=k, value=v)\n",
    "        for k, v in zip(filter_key_list, filter_value_list)\n",
    "    ]\n",
    "    retriever = VectorIndexRetriever(\n",
    "        wiki_vector_index, filters=MetadataFilters(filters=exact_match_filters), top_k=top_k\n",
    "    )\n",
    "    query_engine = RetrieverQueryEngine.from_args(retriever)\n",
    "\n",
    "    response = query_engine.query(query)\n",
    "    return str(response)\n",
    "\n",
    "\n",
    "# auto_retrieve_fn(\"What is about Barbie?\", filter_key_list=[\"movie\"], filter_value_list=[\"Barbie (film)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to wrap our system in a tool in order to integrate it into the larger application.\n",
    "\n",
    "Source Code Here:\n",
    "- [`FunctionTool`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/tools/function_tool.py#L21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = f\"\"\"\\\n",
    "Use this tool to look up semantic information about films.\n",
    "The vector database schema is given below:\n",
    "{vector_store_info.json()}\n",
    "\"\"\"\n",
    "\n",
    "auto_retrieve_tool = FunctionTool.from_defaults(\n",
    "    fn=auto_retrieve_fn,\n",
    "    name=\"auto_retriver\",\n",
    "    description=description,\n",
    "    fn_schema=AutoRetrieveModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"metadata_info\": [{\"name\": \"movie\", \"type\": \"str\", \"description\": \"title of the movie, one of [Barbie (film), Oppenheimer (film)]\"}], \"content_info\": \"semantic information about movies\"}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store_info.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Use this tool to look up semantic information about films.\\nThe vector database schema is given below:\\n{\"metadata_info\": [{\"name\": \"title\", \"type\": \"str\", \"description\": \"title of the movie, one of [Barbie (film), Oppenheimer (film)]\"}], \"content_info\": \"semantic information about movies\"}\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that's left to do is attach the tool to an OpenAIAgent and let it rip!\n",
    "\n",
    "Source Code Here:\n",
    "- [`OpenAIAgent`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/agent/openai_agent.py#L361)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAgent\n",
    "\n",
    "agent = OpenAIAgent.from_tools(\n",
    "    [auto_retrieve_tool],\n",
    "    llm=OpenAI(temperature=0, model=\"gpt-4-0613\"),\n",
    "    verbose=True,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: auto_retriver with args: {\n",
      "  \"query\": \"plot of Barbie movie\",\n",
      "  \"filter_key_list\": [\"title\"],\n",
      "  \"filter_value_list\": [\"Barbie (film)\"]\n",
      "}\n",
      "Got output: The plot of the Barbie movie revolves around Barbie showing her owner how all her dreams could come true.\n",
      "========================\n",
      "The Barbie movie revolves around Barbie showing her owner how all her dreams could come true.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Tell me what happens (briefly) in the Barbie movie.\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BarbenHeimer SQL Tool\n",
    "\n",
    "We'll walk through the steps of creating a natural language to SQL system in the following section.\n",
    "\n",
    "> NOTICE: This does not have parsing on the inputs or intermediary calls to ensure that users are using safe SQL queries. Use this with caution in a production environment without adding specific guardrails from either side of the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q -U sqlalchemy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few steps should be largely straightforward, we'll want to:\n",
    "\n",
    "1. Read in our `.csv` files into `pd.DataFrame` objects\n",
    "2. Create an in-memory `sqlite` powered `sqlalchemy` engine\n",
    "3. Cast our `pd.DataFrame` objects to the SQL engine\n",
    "4. Create an `SQLDatabase` object through LlamaIndex\n",
    "5. Use that to create a `QueryEngineTool` that we can interact with through the `NLSQLTableQueryEngine`!\n",
    "\n",
    "If you get stuck, please consult the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read `.csv` Into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "barbie_df = pd.read_csv(\"barbie_data/barbie.csv\", )\n",
    "oppenheimer_df = pd.read_csv(\"oppenheimer_data/oppenheimer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barbie_df.drop(\"Unnamed: 0\",axis= 1).to_csv(\"barbie_data/barbie.csv\", index=False)\n",
    "# oppenheimer_df.drop(\"Unnamed: 0\",axis= 1).to_csv(\"oppenheimer_data/oppenheimer.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create SQLAlchemy engine with SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"sqlite+pysqlite:///:memory:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert `pd.DataFrame` to SQL tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barbie_df.to_sql(\n",
    "   name=\"barbie_table\",\n",
    "   con=engine\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oppenheimer_df.to_sql(\n",
    "     name=\"oppenheimer_table\",\n",
    "   con=engine\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct a `SQLDatabase` index\n",
    "\n",
    "Source Code Here:\n",
    "- [`SQLDatabase`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/langchain_helpers/sql_wrapper.py#L9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SQLDatabase\n",
    "\n",
    "sql_database = SQLDatabase(\n",
    "    engine=engine,\n",
    "    include_tables=[\"barbie_table\", \"oppenheimer_table\", ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the NLSQLTableQueryEngine interface for all added SQL tables\n",
    "\n",
    "Source Code Here:\n",
    "- [`NLSQLTableQueryEngine`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/indices/struct_store/sql_query.py#L75C1-L75C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\n",
    "\n",
    "sql_query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,\n",
    "    tables=[\"barbie_table\", \"oppenheimer_table\", ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrap It All Up in a `QueryEngineTool`\n",
    "\n",
    "You'll want to ensure you have a descriptive...description. \n",
    "\n",
    "An example is provided here:\n",
    "\n",
    "```\n",
    "\"Useful for translating a natural language query into a SQL query over a table containing: \"\n",
    "\"barbie, containing information related to reviews of the Barbie movie\"\n",
    "\"oppenheimer, containing information related to reviews of the Oppenheimer movie\"\n",
    "```\n",
    "\n",
    "Sorce Code Here: \n",
    "\n",
    "- [`QueryEngineTool`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/tools/query_engine.py#L13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.query_engine import QueryEngineTool\n",
    "\n",
    "sql_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=sql_query_engine,\n",
    "    name=\"review_query\",\n",
    "    description=(\n",
    "       \"\"\"\n",
    "\"Useful for translating a natural language query into a SQL query over a table containing: \"\n",
    "\"barbie_table, containing information related to reviews of the Barbie movie\"\n",
    "\"oppenheimer_table, containing information related to reviews of the Oppenheimer movie\"\n",
    "\"\"\"\n",
    "    ),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = OpenAIAgent.from_tools(\n",
    "    tools=[sql_tool],\n",
    "    llm=OpenAI(temperature=0, model=\"gpt-4-0613\"),\n",
    "    verbose=True,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: review_query with args: {\n",
      "  \"input\": \"What is the average rating of the two films?\"\n",
      "}\n",
      "INFO:llama_index.indices.struct_store.sql_query:> Table desc str: Table 'barbie_table' has columns: index (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "\n",
      "Table 'oppenheimer_table' has columns: index (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "> Table desc str: Table 'barbie_table' has columns: index (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "\n",
      "Table 'oppenheimer_table' has columns: index (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "Got output: The average rating of the film \"Barbie\" is 7.36, and the average rating of the film \"Oppenheimer\" is 8.35.\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"What is the average rating of the two films?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average rating of the film \"Barbie\" is 7.36, and the average rating of the film \"Oppenheimer\" is 8.35.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining The Tools Together\n",
    "\n",
    "Now, we can simple add our tools into the `OpenAIAgent`, and off we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "barbenheimer_agent = OpenAIAgent.from_tools(\n",
    "   tools= [sql_tool,auto_retrieve_tool],\n",
    "   llm=OpenAI(temperature=0, model=\"gpt-4-0613\"),\n",
    "    verbose=True,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: review_query with args: {\n",
      "  \"input\": \"What is the lowest rating of the two films - and can you summarize what the reviewer said?\"\n",
      "}\n",
      "INFO:llama_index.indices.struct_store.sql_query:> Table desc str: Table 'barbie_table' has columns: index (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "\n",
      "Table 'oppenheimer_table' has columns: index (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "> Table desc str: Table 'barbie_table' has columns: index (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "\n",
      "Table 'oppenheimer_table' has columns: index (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "Got output: The lowest rating of the two films is 3.0. The reviewer mentioned that while the production value, cinematography, and acting were good, they felt the movie fell short in terms of the storyline and character development. The reviewer also mentioned that the film may not be suitable for young children due to its themes.\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "response = barbenheimer_agent.chat(\"What is the lowest rating of the two films - and can you summarize what the reviewer said?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Author</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>Review_Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21 July 2023</td>\n",
       "      <td>LoveofLegacy</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Beautiful film, but so preachy\\r\\n</td>\n",
       "      <td>Margot does the best with what she's given, bu...</td>\n",
       "      <td>/review/rw9199947/?ref_=tt_urv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22 July 2023</td>\n",
       "      <td>imseeg</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3 reasons FOR seeing it and 1 reason AGAINST....</td>\n",
       "      <td>The first reason to go see it:</td>\n",
       "      <td>/review/rw9199947/?ref_=tt_urv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22 July 2023</td>\n",
       "      <td>Natcat87</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Too heavy handed\\r\\n</td>\n",
       "      <td>As a woman that grew up with Barbie, I was ver...</td>\n",
       "      <td>/review/rw9199947/?ref_=tt_urv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31 July 2023</td>\n",
       "      <td>ramair350</td>\n",
       "      <td>10.0</td>\n",
       "      <td>As a guy I felt some discomfort, and that's o...</td>\n",
       "      <td>As much as it pains me to give a movie called ...</td>\n",
       "      <td>/review/rw9199947/?ref_=tt_urv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24 July 2023</td>\n",
       "      <td>heatherhilgers</td>\n",
       "      <td>9.0</td>\n",
       "      <td>A Technicolor Dream\\r\\n</td>\n",
       "      <td>Wow, this movie was a love letter to cinema. F...</td>\n",
       "      <td>/review/rw9199947/?ref_=tt_urv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>19 July 2023</td>\n",
       "      <td>mckai-89546</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Best for Ryan Gosling Gives a really great pe...</td>\n",
       "      <td>I am a man but watched this movie it's awesome...</td>\n",
       "      <td>/review/rw9199947/?ref_=tt_urv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>3 August 2023</td>\n",
       "      <td>PennyReviews</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Good Enough\\r\\n</td>\n",
       "      <td>Barbie is a fun summery movie for all ages.</td>\n",
       "      <td>/review/rw9199947/?ref_=tt_urv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>30 July 2023</td>\n",
       "      <td>walfordior</td>\n",
       "      <td>9.0</td>\n",
       "      <td>This is more than just a 'lighthearted comedy...</td>\n",
       "      <td>Barbie is no longer just a toy; rather, this i...</td>\n",
       "      <td>/review/rw9199947/?ref_=tt_urv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>5 August 2023</td>\n",
       "      <td>HuskerNation1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Funny And Good Cast, But Not This \"Great\" Mov...</td>\n",
       "      <td>I wasn't dying to see this, but I felt like I ...</td>\n",
       "      <td>/review/rw9199947/?ref_=tt_urv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>19 July 2023</td>\n",
       "      <td>Mini135</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Barbie is On Her Way to the Oscars\\r\\n</td>\n",
       "      <td>When I first knew there was a Barbie movie in ...</td>\n",
       "      <td>/review/rw9199947/?ref_=tt_urv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Review_Date          Author  Rating  \\\n",
       "0     21 July 2023    LoveofLegacy     6.0   \n",
       "1     22 July 2023          imseeg     7.0   \n",
       "2     22 July 2023        Natcat87     6.0   \n",
       "3     31 July 2023       ramair350    10.0   \n",
       "4     24 July 2023  heatherhilgers     9.0   \n",
       "..             ...             ...     ...   \n",
       "120   19 July 2023     mckai-89546     9.0   \n",
       "121  3 August 2023    PennyReviews     6.0   \n",
       "122   30 July 2023      walfordior     9.0   \n",
       "123  5 August 2023   HuskerNation1     7.0   \n",
       "124   19 July 2023         Mini135     9.0   \n",
       "\n",
       "                                          Review_Title  \\\n",
       "0                   Beautiful film, but so preachy\\r\\n   \n",
       "1     3 reasons FOR seeing it and 1 reason AGAINST....   \n",
       "2                                 Too heavy handed\\r\\n   \n",
       "3     As a guy I felt some discomfort, and that's o...   \n",
       "4                              A Technicolor Dream\\r\\n   \n",
       "..                                                 ...   \n",
       "120   Best for Ryan Gosling Gives a really great pe...   \n",
       "121                                    Good Enough\\r\\n   \n",
       "122   This is more than just a 'lighthearted comedy...   \n",
       "123   Funny And Good Cast, But Not This \"Great\" Mov...   \n",
       "124             Barbie is On Her Way to the Oscars\\r\\n   \n",
       "\n",
       "                                                Review  \\\n",
       "0    Margot does the best with what she's given, bu...   \n",
       "1                       The first reason to go see it:   \n",
       "2    As a woman that grew up with Barbie, I was ver...   \n",
       "3    As much as it pains me to give a movie called ...   \n",
       "4    Wow, this movie was a love letter to cinema. F...   \n",
       "..                                                 ...   \n",
       "120  I am a man but watched this movie it's awesome...   \n",
       "121        Barbie is a fun summery movie for all ages.   \n",
       "122  Barbie is no longer just a toy; rather, this i...   \n",
       "123  I wasn't dying to see this, but I felt like I ...   \n",
       "124  When I first knew there was a Barbie movie in ...   \n",
       "\n",
       "                         Review_Url  \n",
       "0    /review/rw9199947/?ref_=tt_urv  \n",
       "1    /review/rw9199947/?ref_=tt_urv  \n",
       "2    /review/rw9199947/?ref_=tt_urv  \n",
       "3    /review/rw9199947/?ref_=tt_urv  \n",
       "4    /review/rw9199947/?ref_=tt_urv  \n",
       "..                              ...  \n",
       "120  /review/rw9199947/?ref_=tt_urv  \n",
       "121  /review/rw9199947/?ref_=tt_urv  \n",
       "122  /review/rw9199947/?ref_=tt_urv  \n",
       "123  /review/rw9199947/?ref_=tt_urv  \n",
       "124  /review/rw9199947/?ref_=tt_urv  \n",
       "\n",
       "[125 rows x 6 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barbie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barbie_df.Rating.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oppenheimer_df.Rating.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lowest rating of the two films is 3.0. The reviewer mentioned that while the production value, cinematography, and acting were good, they felt the movie fell short in terms of the storyline and character development. The reviewer also mentioned that the film may not be suitable for young children due to its themes.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: review_query with args: {\n",
      "  \"input\": \"How many times do the Barbie reviews mention 'Ken'\"\n",
      "}\n",
      "INFO:llama_index.indices.struct_store.sql_query:> Table desc str: Table 'barbie_table' has columns: index (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "\n",
      "Table 'oppenheimer_table' has columns: index (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "> Table desc str: Table 'barbie_table' has columns: index (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "\n",
      "Table 'oppenheimer_table' has columns: index (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "Got output: The Barbie reviews mention 'Ken' a total of 30 times.\n",
      "========================\n",
      "=== Calling Function ===\n",
      "Calling function: auto_retriver with args: {\n",
      "  \"query\": \"summary of Ken's character in the Barbie movie\",\n",
      "  \"filter_key_list\": [\"title\"],\n",
      "  \"filter_value_list\": [\"Barbie (film)\"]\n",
      "}\n",
      "Got output: Ken in the Barbie movie is depicted as a character who stows away in Barbie's convertible to join her on an adventure. He is involved in a moment where Barbie punches a man for groping her, which leads to their brief arrest. Additionally, Ken has the only power ballad in the film, which is seen as a significant moment by the director.\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "response = barbenheimer_agent.chat(\"How many times do the Barbie reviews mention 'Ken', and what is a summary of his character in the Barbie movie?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Barbie reviews mention 'Ken' a total of 30 times. In the Barbie movie, Ken is depicted as a character who stows away in Barbie's convertible to join her on an adventure. He is involved in a moment where Barbie punches a man for groping her, which leads to their brief arrest. Additionally, Ken has the only power ballad in the film, which is seen as a significant moment by the director.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
